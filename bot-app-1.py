"""
This bot-app-1.py uses the RFP Document stored in Azure. The Assistants API is used to fetch that document and process the user query 
"""


import autogen

from agent_proxy import AgentProxy
from flask import Flask, request, jsonify
import threading
from autogen.agentchat.contrib.gpt_assistant_agent import GPTAssistantAgent

rfp_assistant_id = "asst_Cc0xciWLJxlnU11co3cAuP3H"
rfp_assistant_name = "ContosoEnggRfpAssistant"

rfp_assistant_config = {
    "tools": [
        {"type": "code_interpreter"},
    ],
    "tool_resources": {
        "code_interpreter": {"file_ids": ["assistant-BprDQ5E5xb7vduDioTeMoFwc"]}
    },
}

doc_writer_assistant_config = {
    "tools": [
        {"type": "code_interpreter"},
    ],
    "tool_resources": {
        "code_interpreter": {"file_ids": ["assistant-BprDQ5E5xb7vduDioTeMoFwc"]}
    },
}

user_proxy_system_prompt = """
You represent the Pre Sales Project Engineer tasked with helping compile a Response to an RFP shared in the input.
Once the RFP Response document is completed in all respects, you will save that to the working folder
Once the document is ready, you will conclude the conversation by typing 'TERMINATE'.
"""


group_chat_manager_system_prompt = """
- You represent the Pre Sales Project Engineer tasked with helping compile a Response to an RFP shared in the input. You will follow the workflow steps mentioned below, sequentially:
    #Step1: You will first ask for assistance from the ContosoEnggRfpAssistant to compile the RFP Response document.
    #Step2: Next reach out to CorpComms-Assistant-Proxy to get Customer testimonials and customer case studies.
    #Step3: Finally, you will ask the Document Writer to compile the RFP Response document containing the Engineering part of the proposal and all the Customer case studies and all the Customer testimonials information provided by the CorpComms-Assistant-Proxy.
- Once the Document Writer has compiled the document, let the User_proxy know that the work is complete and do not entertain any further messages.
- Some rules you must follow:
    - Do not move from one step to another until the current step is fully completed. They must be done in a sequence
    - Ensure that all documents are saved in the correct format and location.
"""
# # Configure logging
# logging.basicConfig(filename='app.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
# const.logging = logging
app = Flask(__name__)
# Define the URL of the external service
external_service_url = "http://127.0.0.1:36919/api/autogen"

config_list_gpt4 = autogen.config_list_from_json(
    "OAI_CONFIG_LIST",
    filter_dict={
        "model": ["gpt-4o"],
    },
)

rfp_assistant_system_prompt = """
You are an AI Assistant that helps the Presales team at Contoso Engineering respond to RFPs from potential Customers. 
The user will refer to an RFP Document in .pdf format that is available with you and your task is to create an RFP Response document. 
Use the code interpreter to extract text from the PDF and analyze its content. Employ whatever means to extract the content from the pdf document.
**DO NOT ASK FOR CLARIFYING QUESTIONS. Just provide the response based on your knowledge of the subject to respond to the requirements in the RFP Document.**
Use your domain knowledge to fill in the details required in the Response. 
Ensure that the criteria stipulated by the Customer in the 'Proposal Requirements' section as honored.  
Ensure that every section has a narration of atleast 250 characters. 
When the details in any section merit the use of tables to provide the content, do so. 
Leave the 'Customer Testimonials' and Customer References section alone blank in your response. 
Return the content of the document in Markdown format. Reply TERMINATE in the end when everything is done."
"""

corp_comms_Assistant_Proxy_system_prompt = """
- You are a proxy AI Assistant tasked with gathering Customer testimonials and case studies for the RFP Response document.
- You will be provided with the contents of the RFP Document and you must reach out to the relevant stakeholders to collect the necessary testimonials and case studies.
"""
doc_writer_system_prompt = """You are an AI Assistant playing the role of a Document Writer.
- First ensure you have the following information received in your input before you get started:
    - The Engineering part of the proposal generated by ContosoEnggRfpAssistant in response to the RFP
    - The Customer testimonials and references gathered by CorpComms-Assistant-Proxy
- You have access to the Code Interpreter tool. You must use this tool to create a Microsoft Office Word document (.docx) containing the following information.
    - The **RFP Response prepared by ContosoEnggRfpAssistant that contains the Engineering part of the proposal**. **Ensure you include all the information provided to you. DO NOT leave anything out.**
    - **All the Customer case studies** and **all the Customer testimonials information** provided by the CorpComms-Assistant-Proxy.
- If the **RFP Response** is incomplete, return to the Group chat Manager.
- Save the final content as a Microsoft Word Document .docx format in a shared folder."
"""
# Define user proxy agent
llm_config = {"config_list": config_list_gpt4, "cache_seed": 45}


agent_proxy = AgentProxy(
    name="CorpComms-Assistant-Proxy",
    llm_config=llm_config,
    instructions=corp_comms_Assistant_Proxy_system_prompt,
)

doc_writer = GPTAssistantAgent(
    name="DocumentWriter",
    llm_config=llm_config,
    instructions=doc_writer_system_prompt,
    assistant_config=doc_writer_assistant_config,
)

rfp_assistant = GPTAssistantAgent(
    name=rfp_assistant_name,
    instructions=rfp_assistant_system_prompt,
    llm_config={
        "config_list": config_list_gpt4,
    },
    assistant_config=rfp_assistant_config,
)

user_proxy = autogen.UserProxyAgent(
    name="User_proxy",
    system_message=user_proxy_system_prompt,
    code_execution_config={
        "last_n_messages": 3,
        "work_dir": "groupchat",
        "use_docker": False,
    },
    is_termination_msg=lambda msg: "TERMINATE" in msg["content"],
    # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.
    human_input_mode="NEVER",
)


def extract_content(response) -> str:
    # chat_history
    extracted_content = ""
    chat_history = response.chat_history
    for entry in chat_history:
        if (
            entry.get("role") == "user"
            and entry.get("name") == "CorpComms-Assistant-Proxy"
        ):
            extracted_content = entry.get("content")
            break
    return extracted_content


@app.route("/api/autogen", methods=["POST"])
def handle_autogen_request():
    user_query = request.json.get("query")
    # print(f"Received query: {user_query}")
    # Config.logging.info(f"Received query: {user_query}")
    groupchat = autogen.GroupChat(
        agents=[user_proxy, rfp_assistant, agent_proxy, doc_writer],
        messages=[],
        max_round=5,
        speaker_selection_method="auto",
    )
    manager = autogen.GroupChatManager(
        groupchat=groupchat,
        llm_config=llm_config,
        system_message=group_chat_manager_system_prompt,
    )
    response = user_proxy.initiate_chat(manager, message=user_query)
    # print(f"*******  Response **********: {response}")
    # You can process the response here and return it
    return jsonify({"response": extract_content(response)})


class ServerThread(threading.Thread):
    def __init__(self, app):
        threading.Thread.__init__(self)
        self.app = app
        self.port = None

    def run(self):
        self.port = 36920  # Example port
        app.logger.info(f"Service running on: http://127.0.0.1:{self.port}")
        self.app.run(port=self.port)


if __name__ == "__main__":
    server_thread = ServerThread(app)
    server_thread.start()
    try:
        server_thread.join()
    except (KeyboardInterrupt, SystemExit):
        app.logger.info("Shutting down server...")
        # Add any cleanup code here
